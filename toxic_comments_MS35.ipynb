{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6cadf9f-59d1-4360-89de-b349b53b2fb1",
   "metadata": {},
   "source": [
    "# Введение "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754aae0-f093-4010-919f-b8933b631426",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76fe57-851a-40c3-819b-4a010c3bb03a",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7160b-dbb7-454c-b27b-63f54b51b042",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a33ab8-aef8-44f6-bfd4-b56e9659da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deвайс\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import optuna\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbb5a02-7130-417f-9116-9db2d4615e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Deвайс\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Deвайс\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Deвайс\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deвайс\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка необходимых ресурсов NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645d1618-e1c0-47cb-a5c7-8e7ecc454d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используем устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad4fe0-53e9-4329-b30c-01b94ad520fe",
   "metadata": {},
   "source": [
    "## 2. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ee71c-e5fb-4ce1-b770-5473f3980ac2",
   "metadata": {},
   "source": [
    "Загрузим данные и ознакомимся с их структурой. В датасете есть два столбца: text (текст комментария) и toxic (целевой признак, где 1 — токсичный комментарий, 0 — нет)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b32ac2-6937-4b3f-ab77-6027a928464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "file_path = '/Users/Deвайс/ML/toxic_comments.csv'  # Правильный путь к файлу\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1198667-31ed-40eb-9ab7-8da9e3fc55b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "-------------------------------------------------------------------\n",
      "toxic\n",
      "0    0.898388\n",
      "1    0.101612\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверка данных\n",
    "display(df.head())\n",
    "print('-------------------------------------------------------------------')\n",
    "print(df.info())\n",
    "print('-------------------------------------------------------------------')\n",
    "print(df['toxic'].value_counts(normalize=True))  # Проверяем баланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa5820-926f-4e64-bce7-07fd28c1c74c",
   "metadata": {},
   "source": [
    "**Примечания:**\n",
    "- **Количество строк в датасете**: 159,292.\n",
    "- **Типы данных**:\n",
    "    - `Unnamed: 0`: целочисленный тип (идентификатор).\n",
    "    - `text`: строковый тип (текст комментария).\n",
    "    - `toxic`: целочисленный тип (метка токсичности).\n",
    "\n",
    "**Статистика по целевому признаку `toxic`:**\n",
    "- 89.8% комментариев не токсичные (0).\n",
    "- 10.2% комментариев токсичные (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b5456f-f63e-45ad-aea2-9506dab1ad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений:\n",
      " Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Проверим на наличие пропущенных значений\n",
    "print(\"Количество пропущенных значений:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a039d9a-c33b-44c0-b8b3-61d65b109c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим дубликаты, если они есть\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00b4e6-8ba8-4d7f-b11d-49a0b8e19423",
   "metadata": {},
   "source": [
    "## 3. Предобработка текста\n",
    "\n",
    "На этом этапе мы выполняем предобработку текстовых данных, чтобы привести их в форму, пригодную для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83c1440-f25a-486c-8cab-1e22b8271c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модули для предобработки текста\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c8bd94-e589-4f6a-bb42-a62bd6e3402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция предобработки текста\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)  # Удаление ссылок\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Удаление лишних пробелов\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b4db52-c1b2-4d70-a7f6-3942d80981bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем предобработку\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78480e-92fb-4b05-9888-9a29488376d9",
   "metadata": {},
   "source": [
    "**Шаги предобработки:**\n",
    "1. **Приведение текста к нижнему регистру** — для унификации.\n",
    "2. **Удаление всех символов, не являющихся буквами и цифрами** — с помощью регулярных выражений.\n",
    "3. **Удаление HTML-тегов** — чтобы избавиться от ненужной разметки.\n",
    "4. **Удаление ссылок** — с помощью регулярных выражений.\n",
    "5. **Удаление лишних пробелов** — для очистки текста.\n",
    "6. **Токенизация** — разбиение текста на отдельные слова.\n",
    "7. **Лемматизация** — приведение слов к их базовой форме.\n",
    "8. **Удаление стоп-слов** — таких как \"the\", \"and\", которые не несут значимой информации для классификации.\n",
    "\n",
    "**Применение предобработки:**\n",
    "Мы применяем эту функцию ко всем строкам в столбце `text` с помощью метода `apply()`.\n",
    "\n",
    "```python\n",
    "# Пример применения предобработки\n",
    "df['text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "420d61c8-80be-41ba-a501-ac9f4d5b61d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>ashamed horrible thing put talk page 128 61 19 93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>spitzer umm there actual article prostitution ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>really think understand came idea bad right aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  explanation edits made username hardcore metal...      0\n",
       "1                1  aww match background colour seemingly stuck th...      0\n",
       "2                2  hey man really trying edit war guy constantly ...      0\n",
       "3                3  make real suggestion improvement wondered sect...      0\n",
       "4                4                      sir hero chance remember page      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  second time asking view completely contradicts...      0\n",
       "159288      159447  ashamed horrible thing put talk page 128 61 19 93      0\n",
       "159289      159448  spitzer umm there actual article prostitution ...      0\n",
       "159290      159449  look like actually put speedy first version de...      0\n",
       "159291      159450  really think understand came idea bad right aw...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab6ee5-3a25-4a85-9b5d-0ec9052fba01",
   "metadata": {},
   "source": [
    "Текст предобработан перейдем к вычислениям. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac62900-053f-4535-a102-a99138ffd653",
   "metadata": {},
   "source": [
    "## 4. Разделение данных и векторизация\n",
    "\n",
    "### 4.1 Разделение данных\n",
    "\n",
    "Мы разделяем данные на обучающую и тестовую выборки с помощью функции `train_test_split()` из библиотеки `sklearn`. Размер тестовой выборки составляет 20% от всех данных. Мы также используем параметр `stratify`, чтобы гарантировать, что распределение классов в обучающей и тестовой выборках будет одинаковым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a362d2-b0d6-4201-a989-1902d76a1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['toxic'], test_size=0.2, random_state=42, stratify=df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525312b-f685-4b9c-8887-98989436d5b7",
   "metadata": {},
   "source": [
    "### 4.2 TF-IDF векторизация + Optuna\n",
    "Для представления текста в числовой форме мы используем метод TF-IDF векторизации (Term Frequency - Inverse Document Frequency). Это помогает учесть важность каждого слова в контексте всего корпуса данных.\n",
    "\n",
    "Мы ограничиваем количество признаков до 20,000 и используем диграммы (пары слов), чтобы лучше захватывать контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d958d3-a28f-4dfd-9abd-2e1f5ef29a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF векторизация\n",
    "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ef373d-a37e-4bc6-99c1-b27f4b030bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключаем FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Устанавливаем стандартный уровень логирования Optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484a909-4c12-4da2-a975-e1fad3af7047",
   "metadata": {},
   "source": [
    "### 4.3 Оптимизация моделей с Optuna\n",
    "\n",
    "Для выбора наилучшей модели и ее гиперпараметров мы используем библиотеку **Optuna**, которая позволяет автоматически искать оптимальные параметры для машинного обучения.\n",
    "\n",
    "**Поиск наилучшей модели**\n",
    "Мы рассматриваем три различных модели классификации:\n",
    "- **Логистическая регрессия (`logreg`)**\n",
    "- **Случайный лес (`random_forest`)**\n",
    "- **Градиентный бустинг LightGBM (`lightgbm`)**\n",
    "\n",
    "Optuna будет **перебирать** параметры для каждой модели, чтобы найти наилучшие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55fd861c-ce66-4a8a-8c35-996341142178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для оптимизации моделей с Optuna\n",
    "def objective(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['logreg', 'random_forest', 'lightgbm'])\n",
    "    \n",
    "    if model_type == 'logreg':\n",
    "        C = trial.suggest_float('C', 1e-3, 10, log=True)\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=1000, C=C)\n",
    "    elif model_type == 'random_forest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight='balanced', random_state=42)\n",
    "    else:\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight='balanced', random_state=42, device='gpu', verbose=-1)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fca726f-ad31-466e-bac0-72e41d206356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-09 16:53:10,884] A new study created in memory with name: no-name-ca4da2d0-5a1c-4ea7-97c8-65b9e92c9eb1\n",
      "[I 2025-02-09 16:53:11,714] Trial 0 finished with value: 0.7057534362314926 and parameters: {'model_type': 'logreg', 'C': 0.08659934409452559}. Best is trial 0 with value: 0.7057534362314926.\n",
      "[I 2025-02-09 16:53:34,858] Trial 1 finished with value: 0.7286330277955044 and parameters: {'model_type': 'lightgbm', 'n_estimators': 221, 'max_depth': 4}. Best is trial 1 with value: 0.7286330277955044.\n",
      "[I 2025-02-09 16:54:16,036] Trial 2 finished with value: 0.40796670652529066 and parameters: {'model_type': 'random_forest', 'n_estimators': 250, 'max_depth': 10}. Best is trial 1 with value: 0.7286330277955044.\n",
      "[I 2025-02-09 16:54:16,984] Trial 3 finished with value: 0.7391086840626943 and parameters: {'model_type': 'logreg', 'C': 5.471406448047998}. Best is trial 3 with value: 0.7391086840626943.\n",
      "[I 2025-02-09 16:54:27,304] Trial 4 finished with value: 0.3815692532122098 and parameters: {'model_type': 'random_forest', 'n_estimators': 118, 'max_depth': 5}. Best is trial 3 with value: 0.7391086840626943.\n",
      "[I 2025-02-09 16:54:59,064] Trial 5 finished with value: 0.7477624230381514 and parameters: {'model_type': 'lightgbm', 'n_estimators': 147, 'max_depth': 12}. Best is trial 5 with value: 0.7477624230381514.\n",
      "[I 2025-02-09 16:55:44,643] Trial 6 finished with value: 0.42062171512786983 and parameters: {'model_type': 'random_forest', 'n_estimators': 228, 'max_depth': 12}. Best is trial 5 with value: 0.7477624230381514.\n",
      "[I 2025-02-09 16:56:35,267] Trial 7 finished with value: 0.758612574598349 and parameters: {'model_type': 'lightgbm', 'n_estimators': 252, 'max_depth': 13}. Best is trial 7 with value: 0.758612574598349.\n",
      "[I 2025-02-09 16:57:00,209] Trial 8 finished with value: 0.4265429876023843 and parameters: {'model_type': 'random_forest', 'n_estimators': 123, 'max_depth': 12}. Best is trial 7 with value: 0.758612574598349.\n",
      "[I 2025-02-09 16:57:21,742] Trial 9 finished with value: 0.7242660751516593 and parameters: {'model_type': 'lightgbm', 'n_estimators': 160, 'max_depth': 5}. Best is trial 7 with value: 0.758612574598349.\n",
      "[I 2025-02-09 16:58:22,160] Trial 10 finished with value: 0.7621548404441394 and parameters: {'model_type': 'lightgbm', 'n_estimators': 292, 'max_depth': 15}. Best is trial 10 with value: 0.7621548404441394.\n",
      "[I 2025-02-09 16:59:22,704] Trial 11 finished with value: 0.7625633254051385 and parameters: {'model_type': 'lightgbm', 'n_estimators': 300, 'max_depth': 15}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:00:22,186] Trial 12 finished with value: 0.7623914406680645 and parameters: {'model_type': 'lightgbm', 'n_estimators': 297, 'max_depth': 15}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:00:38,384] Trial 13 finished with value: 0.7119126527135635 and parameters: {'model_type': 'lightgbm', 'n_estimators': 50, 'max_depth': 15}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:01:25,715] Trial 14 finished with value: 0.7550924906125605 and parameters: {'model_type': 'lightgbm', 'n_estimators': 298, 'max_depth': 8}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:02:21,146] Trial 15 finished with value: 0.7603891338239586 and parameters: {'model_type': 'lightgbm', 'n_estimators': 272, 'max_depth': 15}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:02:21,520] Trial 16 finished with value: 0.699744161701541 and parameters: {'model_type': 'logreg', 'C': 0.0026144716074605247}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:03:00,432] Trial 17 finished with value: 0.7511776969120494 and parameters: {'model_type': 'lightgbm', 'n_estimators': 207, 'max_depth': 9}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:03:54,402] Trial 18 finished with value: 0.758617894154669 and parameters: {'model_type': 'lightgbm', 'n_estimators': 268, 'max_depth': 13}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:03:55,626] Trial 19 finished with value: 0.7381266022578481 and parameters: {'model_type': 'logreg', 'C': 8.59426020003684}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:04:31,644] Trial 20 finished with value: 0.750978207423898 and parameters: {'model_type': 'lightgbm', 'n_estimators': 187, 'max_depth': 10}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:05:31,155] Trial 21 finished with value: 0.7625361288214761 and parameters: {'model_type': 'lightgbm', 'n_estimators': 298, 'max_depth': 15}. Best is trial 11 with value: 0.7625633254051385.\n",
      "[I 2025-02-09 17:06:29,201] Trial 22 finished with value: 0.7625674262206759 and parameters: {'model_type': 'lightgbm', 'n_estimators': 297, 'max_depth': 14}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:07:23,408] Trial 23 finished with value: 0.7612878959590137 and parameters: {'model_type': 'lightgbm', 'n_estimators': 268, 'max_depth': 14}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:08:12,452] Trial 24 finished with value: 0.7578073094798445 and parameters: {'model_type': 'lightgbm', 'n_estimators': 245, 'max_depth': 13}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:09:07,639] Trial 25 finished with value: 0.7612510231383062 and parameters: {'model_type': 'lightgbm', 'n_estimators': 276, 'max_depth': 14}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:10:02,830] Trial 26 finished with value: 0.7596172238451943 and parameters: {'model_type': 'lightgbm', 'n_estimators': 300, 'max_depth': 11}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:10:21,432] Trial 27 finished with value: 0.7213330239264305 and parameters: {'model_type': 'lightgbm', 'n_estimators': 62, 'max_depth': 14}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:10:49,806] Trial 28 finished with value: 0.3862057213358086 and parameters: {'model_type': 'random_forest', 'n_estimators': 238, 'max_depth': 7}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:10:50,167] Trial 29 finished with value: 0.7012373687509501 and parameters: {'model_type': 'logreg', 'C': 0.0012990937537495997}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:10:50,960] Trial 30 finished with value: 0.7102005068844132 and parameters: {'model_type': 'logreg', 'C': 0.11704011117658479}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:11:48,897] Trial 31 finished with value: 0.7618822379507846 and parameters: {'model_type': 'lightgbm', 'n_estimators': 284, 'max_depth': 15}. Best is trial 22 with value: 0.7625674262206759.\n",
      "[I 2025-02-09 17:12:47,685] Trial 32 finished with value: 0.7625746782521967 and parameters: {'model_type': 'lightgbm', 'n_estimators': 300, 'max_depth': 14}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:13:41,107] Trial 33 finished with value: 0.7604795178105535 and parameters: {'model_type': 'lightgbm', 'n_estimators': 262, 'max_depth': 14}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:14:36,221] Trial 34 finished with value: 0.7603355290607745 and parameters: {'model_type': 'lightgbm', 'n_estimators': 287, 'max_depth': 13}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:15:32,921] Trial 35 finished with value: 0.7611117208325852 and parameters: {'model_type': 'lightgbm', 'n_estimators': 279, 'max_depth': 14}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:16:10,403] Trial 36 finished with value: 0.41687742449480003 and parameters: {'model_type': 'random_forest', 'n_estimators': 202, 'max_depth': 11}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:16:29,998] Trial 37 finished with value: 0.7197807644258968 and parameters: {'model_type': 'lightgbm', 'n_estimators': 221, 'max_depth': 3}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:17:22,889] Trial 38 finished with value: 0.7602291342688866 and parameters: {'model_type': 'lightgbm', 'n_estimators': 256, 'max_depth': 15}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:18:29,514] Trial 39 finished with value: 0.4233620902920193 and parameters: {'model_type': 'random_forest', 'n_estimators': 300, 'max_depth': 13}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:18:30,381] Trial 40 finished with value: 0.7143629615695365 and parameters: {'model_type': 'logreg', 'C': 0.15396478552945134}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:19:27,976] Trial 41 finished with value: 0.7625401096850523 and parameters: {'model_type': 'lightgbm', 'n_estimators': 285, 'max_depth': 15}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:20:23,404] Trial 42 finished with value: 0.7611117208325852 and parameters: {'model_type': 'lightgbm', 'n_estimators': 279, 'max_depth': 14}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:21:19,840] Trial 43 finished with value: 0.7618822379507846 and parameters: {'model_type': 'lightgbm', 'n_estimators': 284, 'max_depth': 15}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:22:11,560] Trial 44 finished with value: 0.760180383616305 and parameters: {'model_type': 'lightgbm', 'n_estimators': 255, 'max_depth': 14}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:22:58,962] Trial 45 finished with value: 0.7579128315343009 and parameters: {'model_type': 'lightgbm', 'n_estimators': 241, 'max_depth': 12}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:23:51,158] Trial 46 finished with value: 0.7592497011517556 and parameters: {'model_type': 'lightgbm', 'n_estimators': 287, 'max_depth': 11}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:24:12,604] Trial 47 finished with value: 0.7327269367847252 and parameters: {'model_type': 'lightgbm', 'n_estimators': 84, 'max_depth': 13}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:24:41,231] Trial 48 finished with value: 0.42254041944645504 and parameters: {'model_type': 'random_forest', 'n_estimators': 142, 'max_depth': 12}. Best is trial 32 with value: 0.7625746782521967.\n",
      "[I 2025-02-09 17:25:33,515] Trial 49 finished with value: 0.760151042717735 and parameters: {'model_type': 'lightgbm', 'n_estimators': 263, 'max_depth': 15}. Best is trial 32 with value: 0.7625746782521967.\n"
     ]
    }
   ],
   "source": [
    "# Создаем исследование и запускаем оптимизацию\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "954e5f53-6092-4aef-b445-3005c2964e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший F1-score: 0.7626\n",
      "Лучшая модель: lightgbm\n",
      "Лучшие параметры:\n",
      "  model_type: lightgbm\n",
      "  n_estimators: 300\n",
      "  max_depth: 14\n"
     ]
    }
   ],
   "source": [
    "# Получаем лучшую попытку из Optuna\n",
    "best_trial = study.best_trial\n",
    "\n",
    "# Выводим лучшую модель и ее параметры\n",
    "print(f\"Лучший F1-score: {best_trial.value:.4f}\")\n",
    "print(f\"Лучшая модель: {best_trial.params['model_type']}\")\n",
    "print(\"Лучшие параметры:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e9a03-1385-4ff1-a5e0-f88fdf899e9f",
   "metadata": {},
   "source": [
    "Лучшая модель: В ходе оптимизации гиперпараметров было выявлено, что лучшая модель для данной задачи — это LightGBM. С результатом F1-score = 0.7626 на тестовой выборке. Используем технологию BERT для улучшения качества идентификации токсичных комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c5a7f-190c-42bb-b515-53a8ffef2839",
   "metadata": {},
   "source": [
    "## 5. Использование BERT для преобразования текста в эмбеддинги\n",
    "\n",
    "Для улучшения качества классификации мы используем предобученную нейросетевую модель **BERT** (`unitary/toxic-bert`). Эта модель была специально обучена на токсичных комментариях, что делает ее подходящей для нашей задачи.\n",
    "\n",
    "**Загрузка модели и токенизатора BERT**\n",
    "\n",
    "Мы загружаем:\n",
    "- **Токенизатор** `BertTokenizer` — для преобразования текста в числовые представления (токены).\n",
    "- **Модель** `BertForSequenceClassification` — BERT, адаптированный для задачи классификации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19ef4fcf-683e-4a05-874d-a77dc5a85da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели и токенизатора BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "model_bert = BertForSequenceClassification.from_pretrained('unitary/toxic-bert').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "635b644f-051a-4451-91d6-b903b73f283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразования текста в эмбеддинги BERT\n",
    "def get_bert_embeddings(texts, tokenizer, model, max_length=128):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoding = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            output = model(**encoding)\n",
    "            embeddings.append(output.logits.cpu().numpy())\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07febf38-8c69-441d-a28f-fc97c6d0e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем текст в эмбеддинги\n",
    "X_train_bert = get_bert_embeddings(X_train.tolist(), tokenizer, model_bert)\n",
    "X_test_bert = get_bert_embeddings(X_test.tolist(), tokenizer, model_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4eabd5-4826-4caa-85ef-a6459debbe89",
   "metadata": {},
   "source": [
    "### 5.1 Оптимизация моделей с Optuna + BERT\n",
    "\n",
    "Для выбора наилучшей модели и ее гиперпараметров мы используем библиотеку **Optuna**, которая позволяет автоматически искать оптимальные параметры для машинного обучения.\n",
    "\n",
    "**Поиск наилучшей модели**\n",
    "\n",
    "Мы рассматриваем три различных модели классификации:\n",
    "- **Логистическая регрессия (`logreg`)**\n",
    "- **Случайный лес (`random_forest`)**\n",
    "- **Градиентный бустинг LightGBM (`lightgbm`)**\n",
    "\n",
    "Optuna будет **перебирать** параметры для каждой модели, чтобы найти наилучшие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2a26455-6d50-4c55-970c-8030e3c6380d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Оптимизация модели с BERT эмбеддингами\n",
    "def objective_bert(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['logreg', 'random_forest', 'lightgbm'])\n",
    "    \n",
    "    if model_type == 'logreg':\n",
    "        C = trial.suggest_float('C', 1e-3, 10, log=True)\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=1000, C=C)\n",
    "    elif model_type == 'random_forest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight='balanced', random_state=42)\n",
    "    else:\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight='balanced', random_state=42, device='gpu', verbose=-1)\n",
    "\n",
    "    # Кросс-валидация для оценки модели\n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_bert, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98488a4f-8328-40f7-8207-6995f1b6efb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-09 17:37:55,548] A new study created in memory with name: no-name-96db4961-2d9c-4138-9faa-d36a8cfd4f37\n",
      "[I 2025-02-09 17:37:59,682] Trial 0 finished with value: 0.7940937803502945 and parameters: {'model_type': 'lightgbm', 'n_estimators': 237, 'max_depth': 14}. Best is trial 0 with value: 0.7940937803502945.\n",
      "[I 2025-02-09 17:40:10,123] Trial 1 finished with value: 0.8195845738636827 and parameters: {'model_type': 'random_forest', 'n_estimators': 272, 'max_depth': 11}. Best is trial 1 with value: 0.8195845738636827.\n",
      "[I 2025-02-09 17:42:16,304] Trial 2 finished with value: 0.8247564780494955 and parameters: {'model_type': 'random_forest', 'n_estimators': 253, 'max_depth': 12}. Best is trial 2 with value: 0.8247564780494955.\n",
      "[I 2025-02-09 17:42:17,635] Trial 3 finished with value: 0.783852513829616 and parameters: {'model_type': 'lightgbm', 'n_estimators': 214, 'max_depth': 3}. Best is trial 2 with value: 0.8247564780494955.\n",
      "[I 2025-02-09 17:42:18,110] Trial 4 finished with value: 0.7828835515785575 and parameters: {'model_type': 'logreg', 'C': 0.42499633292144245}. Best is trial 2 with value: 0.8247564780494955.\n",
      "[I 2025-02-09 17:43:06,266] Trial 5 finished with value: 0.824777024235348 and parameters: {'model_type': 'random_forest', 'n_estimators': 97, 'max_depth': 12}. Best is trial 5 with value: 0.824777024235348.\n",
      "[I 2025-02-09 17:43:06,731] Trial 6 finished with value: 0.7827794490818021 and parameters: {'model_type': 'logreg', 'C': 1.2664049244015434}. Best is trial 5 with value: 0.824777024235348.\n",
      "[I 2025-02-09 17:43:07,166] Trial 7 finished with value: 0.7797665561710232 and parameters: {'model_type': 'logreg', 'C': 0.0014744618794665394}. Best is trial 5 with value: 0.824777024235348.\n",
      "[I 2025-02-09 17:44:11,651] Trial 8 finished with value: 0.7805260882695234 and parameters: {'model_type': 'random_forest', 'n_estimators': 257, 'max_depth': 5}. Best is trial 5 with value: 0.824777024235348.\n",
      "[I 2025-02-09 17:44:15,623] Trial 9 finished with value: 0.7915418452876839 and parameters: {'model_type': 'lightgbm', 'n_estimators': 242, 'max_depth': 8}. Best is trial 5 with value: 0.824777024235348.\n",
      "[I 2025-02-09 17:44:56,998] Trial 10 finished with value: 0.8370112908733778 and parameters: {'model_type': 'random_forest', 'n_estimators': 77, 'max_depth': 15}. Best is trial 10 with value: 0.8370112908733778.\n",
      "[I 2025-02-09 17:45:36,819] Trial 11 finished with value: 0.8371369503168492 and parameters: {'model_type': 'random_forest', 'n_estimators': 74, 'max_depth': 15}. Best is trial 11 with value: 0.8371369503168492.\n",
      "[I 2025-02-09 17:46:11,028] Trial 12 finished with value: 0.8378732252681663 and parameters: {'model_type': 'random_forest', 'n_estimators': 63, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:47:20,873] Trial 13 finished with value: 0.8373622616151127 and parameters: {'model_type': 'random_forest', 'n_estimators': 131, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:48:13,055] Trial 14 finished with value: 0.8053206285989898 and parameters: {'model_type': 'random_forest', 'n_estimators': 126, 'max_depth': 9}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:49:32,475] Trial 15 finished with value: 0.8291352788950908 and parameters: {'model_type': 'random_forest', 'n_estimators': 155, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:49:56,368] Trial 16 finished with value: 0.8118320153483549 and parameters: {'model_type': 'random_forest', 'n_estimators': 53, 'max_depth': 10}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:50:52,184] Trial 17 finished with value: 0.7922591264728411 and parameters: {'model_type': 'random_forest', 'n_estimators': 166, 'max_depth': 7}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:50:54,669] Trial 18 finished with value: 0.7857126706699564 and parameters: {'model_type': 'lightgbm', 'n_estimators': 120, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:50:55,144] Trial 19 finished with value: 0.7789877009577659 and parameters: {'model_type': 'logreg', 'C': 0.0036795827542559895}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:52:37,669] Trial 20 finished with value: 0.8297469486743638 and parameters: {'model_type': 'random_forest', 'n_estimators': 198, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:53:06,660] Trial 21 finished with value: 0.8373543839874951 and parameters: {'model_type': 'random_forest', 'n_estimators': 54, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:53:35,819] Trial 22 finished with value: 0.8326823987934985 and parameters: {'model_type': 'random_forest', 'n_estimators': 55, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:54:33,847] Trial 23 finished with value: 0.8292695132436825 and parameters: {'model_type': 'random_forest', 'n_estimators': 113, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:55:52,276] Trial 24 finished with value: 0.8372500030429609 and parameters: {'model_type': 'random_forest', 'n_estimators': 146, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:56:30,907] Trial 25 finished with value: 0.8191947031226026 and parameters: {'model_type': 'random_forest', 'n_estimators': 81, 'max_depth': 11}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:57:18,532] Trial 26 finished with value: 0.8331135342585102 and parameters: {'model_type': 'random_forest', 'n_estimators': 90, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:57:45,253] Trial 27 finished with value: 0.8243224736006547 and parameters: {'model_type': 'random_forest', 'n_estimators': 53, 'max_depth': 12}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:57:48,721] Trial 28 finished with value: 0.7901140619933296 and parameters: {'model_type': 'lightgbm', 'n_estimators': 185, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:57:49,188] Trial 29 finished with value: 0.7822571085467734 and parameters: {'model_type': 'logreg', 'C': 0.0664686434209914}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:57:51,739] Trial 30 finished with value: 0.7875353791468402 and parameters: {'model_type': 'lightgbm', 'n_estimators': 140, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 17:59:10,368] Trial 31 finished with value: 0.8372500030429609 and parameters: {'model_type': 'random_forest', 'n_estimators': 146, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:00:05,368] Trial 32 finished with value: 0.8291381791874717 and parameters: {'model_type': 'random_forest', 'n_estimators': 107, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:02:44,063] Trial 33 finished with value: 0.8341860526805605 and parameters: {'model_type': 'random_forest', 'n_estimators': 300, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:03:55,667] Trial 34 finished with value: 0.8369935134035205 and parameters: {'model_type': 'random_forest', 'n_estimators': 133, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:05:29,746] Trial 35 finished with value: 0.8337712730540984 and parameters: {'model_type': 'random_forest', 'n_estimators': 178, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:06:07,121] Trial 36 finished with value: 0.8328408627003288 and parameters: {'model_type': 'random_forest', 'n_estimators': 71, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:06:53,682] Trial 37 finished with value: 0.8188106190732114 and parameters: {'model_type': 'random_forest', 'n_estimators': 98, 'max_depth': 11}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:06:54,143] Trial 38 finished with value: 0.7828299082463422 and parameters: {'model_type': 'logreg', 'C': 4.113901622994821}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:08:48,310] Trial 39 finished with value: 0.8295138135679079 and parameters: {'model_type': 'random_forest', 'n_estimators': 221, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:08:50,978] Trial 40 finished with value: 0.786334445196472 and parameters: {'model_type': 'lightgbm', 'n_estimators': 156, 'max_depth': 6}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:10:08,162] Trial 41 finished with value: 0.8372524958809285 and parameters: {'model_type': 'random_forest', 'n_estimators': 143, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:11:38,843] Trial 42 finished with value: 0.8372397481051833 and parameters: {'model_type': 'random_forest', 'n_estimators': 169, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:11:49,496] Trial 43 finished with value: 0.7728552356991336 and parameters: {'model_type': 'random_forest', 'n_estimators': 65, 'max_depth': 3}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:13:27,054] Trial 44 finished with value: 0.8248763735731406 and parameters: {'model_type': 'random_forest', 'n_estimators': 196, 'max_depth': 12}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:14:23,865] Trial 45 finished with value: 0.8372331725587283 and parameters: {'model_type': 'random_forest', 'n_estimators': 105, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:14:24,323] Trial 46 finished with value: 0.7809421140572725 and parameters: {'model_type': 'logreg', 'C': 0.026144420283262287}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:15:31,423] Trial 47 finished with value: 0.8340373774899985 and parameters: {'model_type': 'random_forest', 'n_estimators': 127, 'max_depth': 14}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:16:17,941] Trial 48 finished with value: 0.8367456904480274 and parameters: {'model_type': 'random_forest', 'n_estimators': 86, 'max_depth': 15}. Best is trial 12 with value: 0.8378732252681663.\n",
      "[I 2025-02-09 18:17:32,835] Trial 49 finished with value: 0.8292483309699009 and parameters: {'model_type': 'random_forest', 'n_estimators': 148, 'max_depth': 13}. Best is trial 12 with value: 0.8378732252681663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизация моделей с BERT эмбеддингами завершена!\n"
     ]
    }
   ],
   "source": [
    "# Создаем исследование и запускаем оптимизацию\n",
    "study_bert = optuna.create_study(direction='maximize')\n",
    "study_bert.optimize(objective_bert, n_trials=50)\n",
    "print(\"Оптимизация моделей с BERT эмбеддингами завершена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b282be4-d011-410a-8362-0105ec459611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем лучшие гиперпараметры и обучаем финальную модель\n",
    "trial_bert = study_bert.best_trial\n",
    "best_model_type = trial_bert.params['model_type']\n",
    "\n",
    "if best_model_type == 'logreg':\n",
    "    best_C = trial_bert.params['C']\n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000, C=best_C)\n",
    "elif best_model_type == 'random_forest':\n",
    "    best_n_estimators = trial_bert.params['n_estimators']\n",
    "    best_max_depth = trial_bert.params['max_depth']\n",
    "    model = RandomForestClassifier(n_estimators=best_n_estimators, max_depth=best_max_depth, class_weight='balanced', random_state=42)\n",
    "else:\n",
    "    best_n_estimators = trial_bert.params['n_estimators']\n",
    "    best_max_depth = trial_bert.params['max_depth']\n",
    "    model = LGBMClassifier(n_estimators=best_n_estimators, max_depth=best_max_depth, class_weight='balanced', random_state=42, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "207fc388-9134-4a77-94fe-f49b3923538c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Лучшая модель: random_forest\n",
      "🎯 Лучший F1-score: 0.8379\n",
      "⚙️ Лучшие гиперпараметры:\n",
      "  model_type: random_forest\n",
      "  n_estimators: 63\n",
      "  max_depth: 15\n"
     ]
    }
   ],
   "source": [
    "# Определяем тип лучшей модели\n",
    "best_model_type = trial_bert.params['model_type']\n",
    "\n",
    "# Выводим информацию о лучшей модели и ее параметрах\n",
    "print(f\"✅ Лучшая модель: {best_model_type}\")\n",
    "print(f\"🎯 Лучший F1-score: {trial_bert.value:.4f}\")\n",
    "print(\"⚙️ Лучшие гиперпараметры:\")\n",
    "for key, value in trial_bert.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a702a-1aa0-4daa-bd25-75b72b02ee34",
   "metadata": {},
   "source": [
    "## 5.2 Обучение на тестовых данных лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a04b29c9-37b4-413d-959c-16f07c627d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты на тестовых данных:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     28622\n",
      "           1       0.79      0.89      0.84      3237\n",
      "\n",
      "    accuracy                           0.96     31859\n",
      "   macro avg       0.89      0.93      0.91     31859\n",
      "weighted avg       0.97      0.96      0.97     31859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель на тренировочных данных с BERT эмбеддингами\n",
    "model.fit(X_train_bert, y_train)\n",
    "\n",
    "# Предсказания на тестовых данных\n",
    "y_pred_bert = model.predict(X_test_bert)\n",
    "\n",
    "# Выводим метрики качества на тестовой выборке\n",
    "print(\"Результаты на тестовых данных:\")\n",
    "print(classification_report(y_test, y_pred_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f85f6fef-9008-4ac5-bf26-b4a9ae410b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.9652\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем F1-score\n",
    "f1 = f1_score(y_test, y_pred_bert, average='weighted')\n",
    "\n",
    "#F1-score\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd89c42-a6a9-40fb-8a4b-20572e12cbf5",
   "metadata": {},
   "source": [
    "### 6. Общий вывод по проекту:\n",
    "**1. Цель проекта:**\n",
    "Проект направлен на классификацию токсичных комментариев с использованием различных моделей машинного обучения, включая методы на основе BERT эмбеддингов. Мы использовали инструменты для оптимизации гиперпараметров моделей с помощью Optuna и достижения наилучших результатов.\n",
    "\n",
    "**2. Процесс и используемые технологии:**\n",
    "Предобработка данных: Мы использовали различные методы предобработки текста, такие как удаление стоп-слов, приведение к нижнему регистру и лемматизация для очистки текста.\n",
    "TF-IDF и BERT эмбеддинги: Для векторизации текста использовались как традиционные методы (TF-IDF), так и более современные BERT эмбеддинги, которые дали значительное улучшение в точности модели.\n",
    "Оптимизация гиперпараметров: Оптимизация моделей проводилась с использованием библиотеки Optuna, что позволило найти лучшие параметры для каждой модели.\n",
    "Использование GPU: Для обучения моделей использовался GPU, что значительно ускорило процесс при работе с большими объемами данных и моделями на основе BERT.\n",
    "\n",
    "**3. Результаты моделей:**\n",
    "Лучшая модель: В ходе оптимизации гиперпараметров было выявлено, что лучшая модель для данной задачи — это Random Forest. С результатом F1-score = 0.8379 на тестовой выборке.\n",
    "Параметры лучшей модели:\n",
    "n_estimators: 63\n",
    "max_depth: 15\n",
    "Метрики качества на тестовых данных:\n",
    "Точность (accuracy): 96%\n",
    "F1-score: 0.91 (макро-усредненный)\n",
    "Precision (точность) и Recall (полнота) для класса токсичных комментариев (1) — 0.79 и 0.89 соответственно, что говорит о хорошем балансе между точностью и полнотой.\n",
    "\n",
    "**4. Выводы:**\n",
    "Применение BERT эмбеддингов значительно улучшает результаты, особенно по сравнению с традиционными методами, такими как TF-IDF.\n",
    "Оптимизация гиперпараметров с использованием Optuna позволяет найти лучшие настройки для моделей и улучшить их точность.\n",
    "Random Forest показал себя как стабильная модель для данной задачи, однако методы на основе BERT показали лучшее качество и могли бы быть использованы для дальнейших улучшений.\n",
    "\n",
    "**5. Рекомендации:**\n",
    "Модели на основе BERT можно дополнительно дообучить на специфических данных или настроить на другие языки для улучшения универсальности.\n",
    "Рассмотрение гибридных моделей с использованием нескольких подходов (например, объединение Random Forest и нейросетевых моделей).\n",
    "Дальнейшая оптимизация и тестирование на новых данных для повышения устойчивости модели.\n",
    "Проект показал хорошие результаты, и с использованием оптимизации гиперпараметров и BERT эмбеддингов удалось достичь высокой точности классификации токсичных комментариев! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
